{
  "sqlfluff__sqlfluff-1625": {
    "instance_id": "sqlfluff__sqlfluff-1625",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/src/sqlfluff/rules/L031.py b/src/sqlfluff/rules/L031.py\nindex 838c6ce5d..2e1454fe3 100644\n--- a/src/sqlfluff/rules/L031.py\n+++ b/src/sqlfluff/rules/L031.py\n@@ -153,6 +153,14 @@ class Rule_L031(BaseRule):\n         # A buffer to keep any violations.\n         violation_buff = []\n \n+        # Check if there are any join clauses. If not, no need to check for aliases.\n+        from_clause_segment = segment.get_child(\"from_clause\")\n+        if from_clause_segment:\n+            join_clauses = list(from_clause_segment.recursive_crawl(\"join_clause\"))\n+            if not join_clauses:\n+                # No joins present, so aliases are acceptable\n+                return None\n+\n         to_check = list(\n             self._filter_table_expressions(base_table, from_expression_elements)\n         )\n@@ -217,3 +225,4 @@ class Rule_L031(BaseRule):\n             )\n \n         return violation_buff or None\n+\ndiff --git a/test/fixtures/rules/std_rule_cases/L031.yml b/test/fixtures/rules/std_rule_cases/L031.yml\nindex 40b41639a..b62217812 100644\n--- a/test/fixtures/rules/std_rule_cases/L031.yml\n+++ b/test/fixtures/rules/std_rule_cases/L031.yml\n@@ -79,12 +79,12 @@ test_fail_avoid_aliases_3:\n     order by o desc\n \n alias_single_char_identifiers:\n-  fail_str: \"select b from tbl as a\"\n-  fix_str: \"select b from tbl\"\n+  # L031 should not trigger when there is no join condition\n+  pass_str: \"select b from tbl as a\"\n \n alias_with_wildcard_identifier:\n-  fail_str: \"select * from tbl as a\"\n-  fix_str: \"select * from tbl\"\n+  # L031 should not trigger when there is no join condition\n+  pass_str: \"select * from tbl as a\"\n \n select_from_values:\n   pass_str: |\n@@ -168,3 +168,4 @@ issue_1589:\n               rnd>=t.v\n          order by rnd\n          limit 1)\n+\n"
  },
  "sqlfluff__sqlfluff-2419": {
    "instance_id": "sqlfluff__sqlfluff-2419",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/src/sqlfluff/rules/L060.py b/src/sqlfluff/rules/L060.py\nindex 836941edc..41ea0187a 100644\n--- a/src/sqlfluff/rules/L060.py\n+++ b/src/sqlfluff/rules/L060.py\n@@ -59,4 +59,9 @@ class Rule_L060(BaseRule):\n             ],\n         )\n \n-        return LintResult(context.segment, [fix])\n+        return LintResult(\n+            context.segment,\n+            [fix],\n+            description=f\"Use 'COALESCE' instead of '{context.segment.raw_upper}'.\",\n+        )\n+\n"
  },
  "sqlfluff__sqlfluff-1733": {
    "instance_id": "sqlfluff__sqlfluff-1733",
    "model_name_or_path": "nano-expert",
    "model_patch": ""
  },
  "sqlfluff__sqlfluff-1517": {
    "instance_id": "sqlfluff__sqlfluff-1517",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/src/sqlfluff/core/parser/grammar/delimited.py b/src/sqlfluff/core/parser/grammar/delimited.py\nindex 39a350373..7e64f60b7 100644\n--- a/src/sqlfluff/core/parser/grammar/delimited.py\n+++ b/src/sqlfluff/core/parser/grammar/delimited.py\n@@ -4,7 +4,7 @@ from typing import Tuple, List\n \n from sqlfluff.core.parser.grammar import Ref\n from sqlfluff.core.parser.segments import BaseSegment, allow_ephemeral\n-from sqlfluff.core.parser.helpers import trim_non_code_segments\n+from sqlfluff.core.parser.helpers import trim_non_code_segments, join_segments_raw\n from sqlfluff.core.parser.match_result import MatchResult\n from sqlfluff.core.parser.match_wrapper import match_wrapper\n from sqlfluff.core.parser.context import ParseContext\n@@ -65,7 +65,13 @@ class Delimited(OneOf):\n \n         # In more detail, match against delimiter, if we match, put a slice\n         # up to that point onto a list of slices. Carry on.\n+        loop_count = 0\n         while True:\n+            loop_count += 1\n+            print(f\"\\n=== Delimited: Loop iteration {loop_count} ===\")\n+            print(f\"seg_buff: {join_segments_raw(seg_buff)!r}\")\n+            print(f\"matched_segments so far: {matched_segments.raw_matched()!r}\")\n+            print(f\"===\\n\")\n             # Check to see whether we've exhausted the buffer, either by iterating through it,\n             # or by consuming all the non-code segments already.\n             # NB: If we're here then we've already tried matching the remaining segments against\n@@ -156,6 +162,11 @@ class Delimited(OneOf):\n                         matched_segments += delimiter_match.matched_segments\n                         # Break this for loop and move on, looking for the next delimiter\n                         seg_buff = delimiter_match.unmatched_segments\n+                        # DEBUG\n+                        print(f\"\\n=== Delimited: After delimiter match ===\")\n+                        print(f\"matched_segments so far: {matched_segments.raw_matched()!r}\")\n+                        print(f\"seg_buff (unmatched): {join_segments_raw(seg_buff)!r}\")\n+                        print(f\"===\\n\")\n                         # Still got some buffer left. Carry on.\n                         continue\n                     # Terminator (or the gap terminator).\n@@ -198,54 +209,4 @@ class Delimited(OneOf):\n                 if self.min_delimiters and len(delimiters) < self.min_delimiters:\n                     return MatchResult.from_unmatched(mutated_segments)\n \n-                # We use the whitespace padded match to hoover up whitespace if enabled,\n-                # and default to the longest matcher. We don't care which one matches.\n-                pre_non_code, trimmed_segments, post_non_code = trim_non_code_segments(\n-                    mutated_segments\n-                )\n-                # Check for whitespace gaps.\n-                # We do this explicitly here rather than relying on an\n-                # untrimmed match so we can handle _whitespace_ explicitly\n-                # compared to other non code segments like placeholders.\n-                if not self.allow_gaps and any(\n-                    seg.is_whitespace for seg in pre_non_code + post_non_code\n-                ):\n-                    return MatchResult.from_unmatched(\n-                        mutated_segments\n-                    )  # pragma: no cover TODO?\n-\n-                with parse_context.deeper_match() as ctx:\n-                    mat, _ = self._longest_trimmed_match(\n-                        trimmed_segments,\n-                        self._elements,\n-                        parse_context=ctx,\n-                        # We've already trimmed\n-                        trim_noncode=False,\n-                    )\n-\n-                if mat:\n-                    # We've got something at the end. Return!\n-                    if mat.unmatched_segments:\n-                        # We have something unmatched and so we should let it also have the trailing elements\n-                        return MatchResult(\n-                            matched_segments.matched_segments\n-                            + pre_non_code\n-                            + mat.matched_segments,\n-                            mat.unmatched_segments + post_non_code,\n-                        )\n-                    else:\n-                        # If there's nothing unmatched in the most recent match, then we can consume the trailing\n-                        # non code segments\n-                        return MatchResult.from_matched(\n-                            matched_segments.matched_segments\n-                            + pre_non_code\n-                            + mat.matched_segments\n-                            + post_non_code,\n-                        )\n-                else:\n-                    # No match at the end, are we allowed to trail? If we are then return,\n-                    # otherwise we fail because we can't match the last element.\n-                    if self.allow_trailing:\n-                        return MatchResult(matched_segments.matched_segments, seg_buff)\n-                    else:\n-                        return MatchResult.from_unmatched(mutated_segments)\n+                # We use the whitespace padded matc\ndiff --git a/src/sqlfluff/core/parser/helpers.py b/src/sqlfluff/core/parser/helpers.py\nindex 718b673ed..0922f495f 100644\n--- a/src/sqlfluff/core/parser/helpers.py\n+++ b/src/sqlfluff/core/parser/helpers.py\n@@ -27,6 +27,16 @@ def check_still_complete(\n     initial_str = join_segments_raw(segments_in)\n     current_str = join_segments_raw(matched_segments + unmatched_segments)\n     if initial_str != current_str:  # pragma: no cover\n+        import traceback\n+        print(\"\\n=== check_still_complete FAILURE ===\")\n+        print(f\"segments_in ({len(segments_in)}): {segments_in}\")\n+        print(f\"matched_segments ({len(matched_segments)}): {matched_segments}\")\n+        print(f\"unmatched_segments ({len(unmatched_segments)}): {unmatched_segments}\")\n+        print(f\"initial_str: {initial_str!r}\")\n+        print(f\"current_str: {current_str!r}\")\n+        print(\"\\nTraceback:\")\n+        traceback.print_stack()\n+        print(\"=== END ===\\n\")\n         raise RuntimeError(\n             \"Dropped elements in sequence matching! {!r} != {!r}\".format(\n                 initial_str, current_str\n@@ -82,3 +92,4 @@ def iter_indices(seq: List, val: Any) -> Iterator[int]:\n     for idx, el in enumerate(seq):\n         if el == val:\n             yield idx\n+\n"
  },
  "sqlfluff__sqlfluff-1763": {
    "instance_id": "sqlfluff__sqlfluff-1763",
    "model_name_or_path": "nano-expert",
    "model_patch": ""
  },
  "marshmallow-code__marshmallow-1359": {
    "instance_id": "marshmallow-code__marshmallow-1359",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/src/marshmallow/fields.py b/src/marshmallow/fields.py\nindex 0b18e7dd..20b67923 100644\n--- a/src/marshmallow/fields.py\n+++ b/src/marshmallow/fields.py\n@@ -1114,7 +1114,7 @@ class DateTime(Field):\n         super()._bind_to_schema(field_name, schema)\n         self.format = (\n             self.format\n-            or getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME)\n+            or (isinstance(schema, SchemaABC) and getattr(schema.opts, self.SCHEMA_OPTS_VAR_NAME, None))\n             or self.DEFAULT_FORMAT\n         )\n \n"
  },
  "marshmallow-code__marshmallow-1343": {
    "instance_id": "marshmallow-code__marshmallow-1343",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/src/marshmallow/marshalling.py b/src/marshmallow/marshalling.py\nindex feb7d1aa..4b40f0d4 100644\n--- a/src/marshmallow/marshalling.py\n+++ b/src/marshmallow/marshalling.py\n@@ -13,7 +13,7 @@ from __future__ import unicode_literals\n import collections\n \n from marshmallow.utils import is_collection, missing, set_value\n-from marshmallow.compat import text_type, iteritems\n+from marshmallow.compat import text_type, iteritems, Mapping\n from marshmallow.exceptions import (\n     ValidationError,\n )\n@@ -250,59 +250,4 @@ class Unmarshaller(ErrorStore):\n \n         ret = dict_class()\n \n-        if not isinstance(data, collections.Mapping):\n-            errors = self.get_errors(index=index)\n-            msg = 'Invalid input type.'\n-            self.error_field_names = [SCHEMA]\n-            errors = self.get_errors()\n-            errors.setdefault(SCHEMA, []).append(msg)\n-            return None\n-        else:\n-            partial_is_collection = is_collection(partial)\n-            for attr_name, field_obj in iteritems(fields_dict):\n-                if field_obj.dump_only:\n-                    continue\n-                raw_value = data.get(attr_name, missing)\n-                field_name = attr_name\n-                if raw_value is missing and field_obj.load_from:\n-                    field_name = field_obj.load_from\n-                    raw_value = data.get(field_obj.load_from, missing)\n-                if raw_value is missing:\n-                    # Ignore missing field if we're allowed to.\n-                    if (\n-                        partial is True or\n-                        (partial_is_collection and attr_name in partial)\n-                    ):\n-                        continue\n-                    _miss = field_obj.missing\n-                    raw_value = _miss() if callable(_miss) else _miss\n-                if raw_value is missing and not field_obj.required:\n-                    continue\n-\n-                getter = lambda val: field_obj.deserialize(\n-                    val,\n-                    field_obj.load_from or attr_name,\n-                    data\n-                )\n-                value = self.call_and_store(\n-                    getter_func=getter,\n-                    data=raw_value,\n-                    field_name=field_name,\n-                    field_obj=field_obj,\n-                    index=(index if index_errors else None)\n-                )\n-                if value is not missing:\n-                    key = fields_dict[attr_name].attribute or attr_name\n-                    set_value(ret, key, value)\n \n-        if self.errors and not self._pending:\n-            raise ValidationError(\n-                self.errors,\n-                field_names=self.error_field_names,\n-                fields=self.error_fields,\n-                data=ret,\n-            )\n-        return ret\n-\n-    # Make an instance callable\n-    __call__ = deserialize\n"
  },
  "pvlib__pvlib-python-1707": {
    "instance_id": "pvlib__pvlib-python-1707",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pvlib/singlediode.py b/pvlib/singlediode.py\nindex 81d6ce3..abc5c12 100644\n--- a/pvlib/singlediode.py\n+++ b/pvlib/singlediode.py\n@@ -56,7 +56,7 @@ def estimate_voc(photocurrent, saturation_current, nNsVth):\n \n def bishop88(diode_voltage, photocurrent, saturation_current,\n              resistance_series, resistance_shunt, nNsVth, d2mutau=0,\n-             NsVbi=np.Inf, breakdown_factor=0., breakdown_voltage=-5.5,\n+             NsVbi=np.inf, breakdown_factor=0., breakdown_voltage=-5.5,\n              breakdown_exp=3.28, gradients=False):\n     r\"\"\"\n     Explicit calculation of points on the IV curve described by the single\n@@ -204,7 +204,7 @@ def bishop88(diode_voltage, photocurrent, saturation_current,\n \n def bishop88_i_from_v(voltage, photocurrent, saturation_current,\n                       resistance_series, resistance_shunt, nNsVth,\n-                      d2mutau=0, NsVbi=np.Inf, breakdown_factor=0.,\n+                      d2mutau=0, NsVbi=np.inf, breakdown_factor=0.,\n                       breakdown_voltage=-5.5, breakdown_exp=3.28,\n                       method='newton'):\n     \"\"\"\n@@ -233,451 +233,4 @@ def bishop88_i_from_v(voltage, photocurrent, saturation_current,\n         :math:`\\\\mu \\\\tau`. [V]\n     NsVbi : numeric, default np.inf\n         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n-        (a-Si) modules that is the product of the PV module number of series\n-        cells ``Ns`` and the builtin voltage ``Vbi`` of the intrinsic layer.\n-        [V].\n-    breakdown_factor : numeric, default 0\n-        fraction of ohmic current involved in avalanche breakdown :math:`a`.\n-        Default of 0 excludes the reverse bias term from the model. [unitless]\n-    breakdown_voltage : numeric, default -5.5\n-        reverse breakdown voltage of the photovoltaic junction :math:`V_{br}`\n-        [V]\n-    breakdown_exp : numeric, default 3.28\n-        avalanche breakdown exponent :math:`m` [unitless]\n-    method : str, default 'newton'\n-       Either ``'newton'`` or ``'brentq'``. ''method'' must be ``'newton'``\n-       if ``breakdown_factor`` is not 0.\n-\n-    Returns\n-    -------\n-    current : numeric\n-        current (I) at the specified voltage (V). [A]\n-    \"\"\"\n-    # collect args\n-    args = (photocurrent, saturation_current, resistance_series,\n-            resistance_shunt, nNsVth, d2mutau, NsVbi,\n-            breakdown_factor, breakdown_voltage, breakdown_exp)\n-\n-    def fv(x, v, *a):\n-        # calculate voltage residual given diode voltage \"x\"\n-        return bishop88(x, *a)[1] - v\n-\n-    if method.lower() == 'brentq':\n-        # first bound the search using voc\n-        voc_est = estimate_voc(photocurrent, saturation_current, nNsVth)\n-\n-        # brentq only works with scalar inputs, so we need a set up function\n-        # and np.vectorize to repeatedly call the optimizer with the right\n-        # arguments for possible array input\n-        def vd_from_brent(voc, v, iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n-                          breakdown_factor, breakdown_voltage, breakdown_exp):\n-            return brentq(fv, 0.0, voc,\n-                          args=(v, iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n-                                breakdown_factor, breakdown_voltage,\n-                                breakdown_exp))\n-\n-        vd_from_brent_vectorized = np.vectorize(vd_from_brent)\n-        vd = vd_from_brent_vectorized(voc_est, voltage, *args)\n-    elif method.lower() == 'newton':\n-        # make sure all args are numpy arrays if max size > 1\n-        # if voltage is an array, then make a copy to use for initial guess, v0\n-        args, v0 = _prepare_newton_inputs((voltage,), args, voltage)\n-        vd = newton(func=lambda x, *a: fv(x, voltage, *a), x0=v0,\n-                    fprime=lambda x, *a: bishop88(x, *a, gradients=True)[4],\n-                    args=args)\n-    else:\n-        raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n-    return bishop88(vd, *args)[0]\n-\n-\n-def bishop88_v_from_i(current, photocurrent, saturation_current,\n-                      resistance_series, resistance_shunt, nNsVth,\n-                      d2mutau=0, NsVbi=np.Inf, breakdown_factor=0.,\n-                      breakdown_voltage=-5.5, breakdown_exp=3.28,\n-                      method='newton'):\n-    \"\"\"\n-    Find voltage given any current.\n-\n-    Parameters\n-    ----------\n-    current : numeric\n-        current (I) in amperes [A]\n-    photocurrent : numeric\n-        photogenerated current (Iph or IL) [A]\n-    saturation_current : numeric\n-        diode dark or saturation current (Io or Isat) [A]\n-    resistance_series : numeric\n-        series resistance (Rs) in [Ohm]\n-    resistance_shunt : numeric\n-        shunt resistance (Rsh) [Ohm]\n-    nNsVth : numeric\n-        product of diode ideality factor (n), number of series cells (Ns), and\n-        thermal voltage (Vth = k_b * T / q_e) in volts [V]\n-    d2mutau : numeric, default 0\n-        PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n-        (a-Si) modules that accounts for recombination current in the\n-        intrinsic layer. The value is the ratio of intrinsic layer thickness\n-        squared :math:`d^2` to the diffusion length of charge carriers\n-        :math:`\\\\mu \\\\tau`. [V]\n-    NsVbi : numeric, default np.inf\n-        PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n-        (a-Si) modules that is the product of the PV module number of series\n-        cells ``Ns`` and the builtin voltage ``Vbi`` of the intrinsic layer.\n-        [V].\n-    breakdown_factor : numeric, default 0\n-        fraction of ohmic current involved in avalanche breakdown :math:`a`.\n-        Default of 0 excludes the reverse bias term from the model. [unitless]\n-    breakdown_voltage : numeric, default -5.5\n-        reverse breakdown voltage of the photovoltaic junction :math:`V_{br}`\n-        [V]\n-    breakdown_exp : numeric, default 3.28\n-        avalanche breakdown exponent :math:`m` [unitless]\n-    method : str, default 'newton'\n-       Either ``'newton'`` or ``'brentq'``. ''method'' must be ``'newton'``\n-       if ``breakdown_factor`` is not 0.\n-\n-    Returns\n-    -------\n-    voltage : numeric\n-        voltage (V) at the specified current (I) in volts [V]\n-    \"\"\"\n-    # collect args\n-    args = (photocurrent, saturation_current, resistance_series,\n-            resistance_shunt, nNsVth, d2mutau, NsVbi, breakdown_factor,\n-            breakdown_voltage, breakdown_exp)\n-    # first bound the search using voc\n-    voc_est = estimate_voc(photocurrent, saturation_current, nNsVth)\n-\n-    def fi(x, i, *a):\n-        # calculate current residual given diode voltage \"x\"\n-        return bishop88(x, *a)[0] - i\n-\n-    if method.lower() == 'brentq':\n-        # brentq only works with scalar inputs, so we need a set up function\n-        # and np.vectorize to repeatedly call the optimizer with the right\n-        # arguments for possible array input\n-        def vd_from_brent(voc, i, iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n-                          breakdown_factor, breakdown_voltage, breakdown_exp):\n-            return brentq(fi, 0.0, voc,\n-                          args=(i, iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n-                                breakdown_factor, breakdown_voltage,\n-                                breakdown_exp))\n-\n-        vd_from_brent_vectorized = np.vectorize(vd_from_brent)\n-        vd = vd_from_brent_vectorized(voc_est, current, *args)\n-    elif method.lower() == 'newton':\n-        # make sure all args are numpy arrays if max size > 1\n-        # if voc_est is an array, then make a copy to use for initial guess, v0\n-        args, v0 = _prepare_newton_inputs((current,), args, voc_est)\n-        vd = newton(func=lambda x, *a: fi(x, current, *a), x0=v0,\n-                    fprime=lambda x, *a: bishop88(x, *a, gradients=True)[3],\n-                    args=args)\n-    else:\n-        raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n-    return bishop88(vd, *args)[1]\n-\n-\n-def bishop88_mpp(photocurrent, saturation_current, resistance_series,\n-                 resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.Inf,\n-                 breakdown_factor=0., breakdown_voltage=-5.5,\n-                 breakdown_exp=3.28, method='newton'):\n-    \"\"\"\n-    Find max power point.\n-\n-    Parameters\n-    ----------\n-    photocurrent : numeric\n-        photogenerated current (Iph or IL) [A]\n-    saturation_current : numeric\n-        diode dark or saturation current (Io or Isat) [A]\n-    resistance_series : numeric\n-        series resistance (Rs) in [Ohm]\n-    resistance_shunt : numeric\n-        shunt resistance (Rsh) [Ohm]\n-    nNsVth : numeric\n-        product of diode ideality factor (n), number of series cells (Ns), and\n-        thermal voltage (Vth = k_b * T / q_e) in volts [V]\n-    d2mutau : numeric, default 0\n-        PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n-        (a-Si) modules that accounts for recombination current in the\n-        intrinsic layer. The value is the ratio of intrinsic layer thickness\n-        squared :math:`d^2` to the diffusion length of charge carriers\n-        :math:`\\\\mu \\\\tau`. [V]\n-    NsVbi : numeric, default np.inf\n-        PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n-        (a-Si) modules that is the product of the PV module number of series\n-        cells ``Ns`` and the builtin voltage ``Vbi`` of the intrinsic layer.\n-        [V].\n-    breakdown_factor : numeric, default 0\n-        fraction of ohmic current involved in avalanche breakdown :math:`a`.\n-        Default of 0 excludes the reverse bias term from the model. [unitless]\n-    breakdown_voltage : numeric, default -5.5\n-        reverse breakdown voltage of the photovoltaic junction :math:`V_{br}`\n-        [V]\n-    breakdown_exp : numeric, default 3.28\n-        avalanche breakdown exponent :math:`m` [unitless]\n-    method : str, default 'newton'\n-       Eith"
  },
  "pvlib__pvlib-python-1072": {
    "instance_id": "pvlib__pvlib-python-1072",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\nindex fecc930..90e7397 100644\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -1942,7 +1942,7 @@ def singlediode(photocurrent, saturation_current, resistance_series,\n \n \n def max_power_point(photocurrent, saturation_current, resistance_series,\n-                    resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.Inf,\n+                    resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.inf,\n                     method='brentq'):\n     \"\"\"\n     Given the single diode equation coefficients, calculates the maximum power\n@@ -1989,7 +1989,7 @@ def max_power_point(photocurrent, saturation_current, resistance_series,\n     \"\"\"\n     i_mp, v_mp, p_mp = _singlediode.bishop88_mpp(\n         photocurrent, saturation_current, resistance_series,\n-        resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.Inf,\n+        resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.inf,\n         method=method.lower()\n     )\n     if isinstance(photocurrent, pd.Series):\ndiff --git a/pvlib/singlediode.py b/pvlib/singlediode.py\nindex b800e1c..c33dd0a 100644\n--- a/pvlib/singlediode.py\n+++ b/pvlib/singlediode.py\n@@ -56,7 +56,7 @@ def estimate_voc(photocurrent, saturation_current, nNsVth):\n \n def bishop88(diode_voltage, photocurrent, saturation_current,\n              resistance_series, resistance_shunt, nNsVth, d2mutau=0,\n-             NsVbi=np.Inf, breakdown_factor=0., breakdown_voltage=-5.5,\n+             NsVbi=np.inf, breakdown_factor=0., breakdown_voltage=-5.5,\n              breakdown_exp=3.28, gradients=False):\n     r\"\"\"\n     Explicit calculation of points on the IV curve described by the single\n@@ -204,7 +204,7 @@ def bishop88(diode_voltage, photocurrent, saturation_current,\n \n def bishop88_i_from_v(voltage, photocurrent, saturation_current,\n                       resistance_series, resistance_shunt, nNsVth,\n-                      d2mutau=0, NsVbi=np.Inf, breakdown_factor=0.,\n+                      d2mutau=0, NsVbi=np.inf, breakdown_factor=0.,\n                       breakdown_voltage=-5.5, breakdown_exp=3.28,\n                       method='newton'):\n     \"\"\"\n@@ -292,7 +292,7 @@ def bishop88_i_from_v(voltage, photocurrent, saturation_current,\n \n def bishop88_v_from_i(current, photocurrent, saturation_current,\n                       resistance_series, resistance_shunt, nNsVth,\n-                      d2mutau=0, NsVbi=np.Inf, breakdown_factor=0.,\n+                      d2mutau=0, NsVbi=np.inf, breakdown_factor=0.,\n                       breakdown_voltage=-5.5, breakdown_exp=3.28,\n                       method='newton'):\n     \"\"\"\n@@ -378,7 +378,7 @@ def bishop88_v_from_i(current, photocurrent, saturation_current,\n \n \n def bishop88_mpp(photocurrent, saturation_current, resistance_series,\n-                 resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.Inf,\n+                 resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.inf,\n                  breakdown_factor=0., breakdown_voltage=-5.5,\n                  breakdown_exp=3.28, method='newton'):\n     \"\"\"\ndiff --git a/pvlib/temperature.py b/pvlib/temperature.py\nindex 1d98736..8214cb1 100644\n--- a/pvlib/temperature.py\n+++ b/pvlib/temperature.py\n@@ -599,7 +599,7 @@ def fuentes(poa_global, temp_air, wind_speed, noct_installed, module_height=5,\n     # n.b. the way Fuentes calculates the first timedelta makes it seem like\n     # the value doesn't matter -- rather than recreate it here, just assume\n     # it's the same as the second timedelta:\n-    timedelta_hours = np.diff(poa_global.index).astype(float) / 1e9 / 60 / 60\n+    timedelta_hours = np.diff(poa_global.index).astype('timedelta64[ns]').astype(float) / 1e9 / 60 / 60\n     timedelta_hours = np.append([timedelta_hours[0]], timedelta_hours)\n \n     tamb_array = temp_air + 273.15\ndiff --git a/pvlib/tests/test_singlediode.py b/pvlib/tests/test_singlediode.py\nindex ee20e48..a5186f4 100644\n--- a/pvlib/tests/test_singlediode.py\n+++ b/pvlib/tests/test_singlediode.py\n@@ -203,7 +203,7 @@ def test_pvsyst_recombination_loss(method, poa, temp_cell, expected, tol):\n         # other conditions with breakdown model on and recombination model off\n         (\n             (1.e-4, -5.5, 3.28),\n-            (0., np.Inf),\n+            (0., np.inf),\n             POA,\n             TCELL,\n             {\n"
  },
  "pvlib__pvlib-python-1606": {
    "instance_id": "pvlib__pvlib-python-1606",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pvlib/tools.py b/pvlib/tools.py\nindex 991568f..afa6fe3 100644\n--- a/pvlib/tools.py\n+++ b/pvlib/tools.py\n@@ -348,6 +348,20 @@ def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-8):\n     df['VH'] = upper\n     df['VL'] = lower\n \n+    # Handle cases where bounds are equal or very close\n+    # If upper == lower, the optimal point is at the bound\n+    bounds_equal = np.abs(df['VH'] - df['VL']) < atol\n+    \n+    if np.all(bounds_equal):\n+        # All bounds are equal, return the function value at the bound\n+        try:\n+            func_result = func(df, 'VL')\n+            x = np.where(np.isnan(func_result), np.nan, df['VL'])\n+        except KeyError:\n+            func_result = np.full_like(upper, np.nan)\n+            x = func_result.copy()\n+        return func_result, x\n+    \n     converged = False\n     iterations = 0\n \n@@ -355,8 +369,10 @@ def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-8):\n     with warnings.catch_warnings():\n         warnings.filterwarnings(action='ignore',\n                                 message='All-NaN slice encountered')\n+        # Only calculate iterlimit for cases where bounds are not equal\n+        # to avoid divide by zero\n         iterlimit = 1 + np.nanmax(\n-            np.trunc(np.log(atol / (df['VH'] - df['VL'])) / np.log(phim1)))\n+            np.trunc(np.log(atol / np.where(bounds_equal, np.nan, df['VH'] - df['VL'])) / np.log(phim1)))\n \n     while not converged and (iterations <= iterlimit):\n \n"
  },
  "pvlib__pvlib-python-1854": {
    "instance_id": "pvlib__pvlib-python-1854",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pvlib/pvsystem.py b/pvlib/pvsystem.py\nindex c277a77..3c7eb50 100644\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -220,6 +220,9 @@ class PVSystem:\n                 strings_per_inverter,\n                 array_losses_parameters,\n             ),)\n+        elif isinstance(arrays, Array):\n+            # Single Array instance passed, wrap in tuple\n+            self.arrays = (arrays,)\n         elif len(arrays) == 0:\n             raise ValueError(\"PVSystem must have at least one Array. \"\n                              \"If you want to create a PVSystem instance \"\n@@ -270,2743 +273,4 @@ class PVSystem:\n             raise ValueError(\"Length mismatch for per-array parameter\")\n         return values\n \n-    @_unwrap_single_value\n-    def _infer_cell_type(self):\n-        \"\"\"\n-        Examines module_parameters and maps the Technology key for the CEC\n-        database and the Material key for the Sandia database to a common\n-        list of strings for cell type.\n-\n-        Returns\n-        -------\n-        cell_type: str\n-        \"\"\"\n-        return tuple(array._infer_cell_type() for array in self.arrays)\n-\n-    @_unwrap_single_value\n-    def get_aoi(self, solar_zenith, solar_azimuth):\n-        \"\"\"Get the angle of incidence on the Array(s) in the system.\n-\n-        Parameters\n-        ----------\n-        solar_zenith : float or Series.\n-            Solar zenith angle.\n-        solar_azimuth : float or Series.\n-            Solar azimuth angle.\n-\n-        Returns\n-        -------\n-        aoi : Series or tuple of Series\n-            The angle of incidence\n-        \"\"\"\n-\n-        return tuple(array.get_aoi(solar_zenith, solar_azimuth)\n-                     for array in self.arrays)\n-\n-    @_unwrap_single_value\n-    def get_irradiance(self, solar_zenith, solar_azimuth, dni, ghi, dhi,\n-                       dni_extra=None, airmass=None, albedo=None,\n-                       model='haydavies', **kwargs):\n-        \"\"\"\n-        Uses the :py:func:`irradiance.get_total_irradiance` function to\n-        calculate the plane of array irradiance components on the tilted\n-        surfaces defined by each array's ``surface_tilt`` and\n-        ``surface_azimuth``.\n-\n-        Parameters\n-        ----------\n-        solar_zenith : float or Series\n-            Solar zenith angle.\n-        solar_azimuth : float or Series\n-            Solar azimuth angle.\n-        dni : float or Series or tuple of float or Series\n-            Direct Normal Irradiance. [W/m2]\n-        ghi : float or Series or tuple of float or Series\n-            Global horizontal irradiance. [W/m2]\n-        dhi : float or Series or tuple of float or Series\n-            Diffuse horizontal irradiance. [W/m2]\n-        dni_extra : None, float, Series or tuple of float or Series,\\\n-            default None\n-            Extraterrestrial direct normal irradiance. [W/m2]\n-        airmass : None, float or Series, default None\n-            Airmass. [unitless]\n-        albedo : None, float or Series, default None\n-            Ground surface albedo. [unitless]\n-        model : String, default 'haydavies'\n-            Irradiance model.\n-\n-        kwargs\n-            Extra parameters passed to :func:`irradiance.get_total_irradiance`.\n-\n-        Notes\n-        -----\n-        Each of `dni`, `ghi`, and `dni` parameters may be passed as a tuple\n-        to provide different irradiance for each array in the system. If not\n-        passed as a tuple then the same value is used for input to each Array.\n-        If passed as a tuple the length must be the same as the number of\n-        Arrays.\n-\n-        Returns\n-        -------\n-        poa_irradiance : DataFrame or tuple of DataFrame\n-            Column names are: ``'poa_global', 'poa_direct', 'poa_diffuse',\n-            'poa_sky_diffuse', 'poa_ground_diffuse'``.\n-\n-        See also\n-        --------\n-        pvlib.irradiance.get_total_irradiance\n-        \"\"\"\n-        dni = self._validate_per_array(dni, system_wide=True)\n-        ghi = self._validate_per_array(ghi, system_wide=True)\n-        dhi = self._validate_per_array(dhi, system_wide=True)\n-\n-        albedo = self._validate_per_array(albedo, system_wide=True)\n-\n-        return tuple(\n-            array.get_irradiance(solar_zenith, solar_azimuth,\n-                                 dni, ghi, dhi,\n-                                 dni_extra=dni_extra, airmass=airmass,\n-                                 albedo=albedo, model=model, **kwargs)\n-            for array, dni, ghi, dhi, albedo in zip(\n-                self.arrays, dni, ghi, dhi, albedo\n-            )\n-        )\n-\n-    @_unwrap_single_value\n-    def get_iam(self, aoi, iam_model='physical'):\n-        \"\"\"\n-        Determine the incidence angle modifier using the method specified by\n-        ``iam_model``.\n-\n-        Parameters for the selected IAM model are expected to be in\n-        ``PVSystem.module_parameters``. Default parameters are available for\n-        the 'physical', 'ashrae' and 'martin_ruiz' models.\n-\n-        Parameters\n-        ----------\n-        aoi : numeric or tuple of numeric\n-            The angle of incidence in degrees.\n-\n-        aoi_model : string, default 'physical'\n-            The IAM model to be used. Valid strings are 'physical', 'ashrae',\n-            'martin_ruiz', 'sapm' and 'interp'.\n-        Returns\n-        -------\n-        iam : numeric or tuple of numeric\n-            The AOI modifier.\n-\n-        Raises\n-        ------\n-        ValueError\n-            if `iam_model` is not a valid model name.\n-        \"\"\"\n-        aoi = self._validate_per_array(aoi)\n-        return tuple(array.get_iam(aoi, iam_model)\n-                     for array, aoi in zip(self.arrays, aoi))\n-\n-    @_unwrap_single_value\n-    def get_cell_temperature(self, poa_global, temp_air, wind_speed, model,\n-                             effective_irradiance=None):\n-        \"\"\"\n-        Determine cell temperature using the method specified by ``model``.\n-\n-        Parameters\n-        ----------\n-        poa_global : numeric or tuple of numeric\n-            Total incident irradiance in W/m^2.\n-\n-        temp_air : numeric or tuple of numeric\n-            Ambient dry bulb temperature in degrees C.\n-\n-        wind_speed : numeric or tuple of numeric\n-            Wind speed in m/s.\n-\n-        model : str\n-            Supported models include ``'sapm'``, ``'pvsyst'``,\n-            ``'faiman'``, ``'fuentes'``, and ``'noct_sam'``\n-\n-        effective_irradiance : numeric or tuple of numeric, optional\n-            The irradiance that is converted to photocurrent in W/m^2.\n-            Only used for some models.\n-\n-        Returns\n-        -------\n-        numeric or tuple of numeric\n-            Values in degrees C.\n-\n-        See Also\n-        --------\n-        Array.get_cell_temperature\n-\n-        Notes\n-        -----\n-        The `temp_air` and `wind_speed` parameters may be passed as tuples\n-        to provide different values for each Array in the system. If passed as\n-        a tuple the length must be the same as the number of Arrays. If not\n-        passed as a tuple then the same value is used for each Array.\n-        \"\"\"\n-        poa_global = self._validate_per_array(poa_global)\n-        temp_air = self._validate_per_array(temp_air, system_wide=True)\n-        wind_speed = self._validate_per_array(wind_speed, system_wide=True)\n-        # Not used for all models, but Array.get_cell_temperature handles it\n-        effective_irradiance = self._validate_per_array(effective_irradiance,\n-                                                        system_wide=True)\n-\n-        return tuple(\n-            array.get_cell_temperature(poa_global, temp_air, wind_speed,\n-                                       model, effective_irradiance)\n-            for array, poa_global, temp_air, wind_speed, effective_irradiance\n-            in zip(\n-                self.arrays, poa_global, temp_air, wind_speed,\n-                effective_irradiance\n-            )\n-        )\n-\n-    @_unwrap_single_value\n-    def calcparams_desoto(self, effective_irradiance, temp_cell):\n-        \"\"\"\n-        Use the :py:func:`calcparams_desoto` function, the input\n-        parameters and ``self.module_parameters`` to calculate the\n-        module currents and resistances.\n-\n-        Parameters\n-        ----------\n-        effective_irradiance : numeric or tuple of numeric\n-            The irradiance (W/m2) that is converted to photocurrent.\n-\n-        temp_cell : float or Series or tuple of float or Series\n-            The average cell temperature of cells within a module in C.\n-\n-        Returns\n-        -------\n-        See pvsystem.calcparams_desoto for details\n-        \"\"\"\n-        effective_irradiance = self._validate_per_array(effective_irradiance)\n-        temp_cell = self._validate_per_array(temp_cell)\n-\n-        build_kwargs = functools.partial(\n-            _build_kwargs,\n-            ['a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n-             'R_s', 'alpha_sc', 'EgRef', 'dEgdT',\n-             'irrad_ref', 'temp_ref']\n-        )\n-\n-        return tuple(\n-            calcparams_desoto(\n-                effective_irradiance, temp_cell,\n-                **build_kwargs(array.module_parameters)\n-            )\n-            for array, effective_irradiance, temp_cell\n-            in zip(self.arrays, effective_irradiance, temp_cell)\n-        )\n-\n-    @_unwrap_single_value\n-    def calcparams_cec(self, effective_irradiance, temp_cell):\n-        \"\"\"\n-        Use the :py:func:`calcparams_cec` function, the input\n-        parameters and ``self.module_parameters`` to calculate the\n-        module currents and resistances.\n-\n-        Parameters\n-        ----------\n-        effective_irradiance : numeric or tuple of numeric\n-            The irradiance (W/m2) that is converted to photocurrent.\n-\n-        temp_cell : float or Series or tuple of float or Series\n-            The average cell temperature of cells within a module in C.\n-\n-        Returns\n-        -------\n-        See pvsystem.cal"
  },
  "pvlib__pvlib-python-1154": {
    "instance_id": "pvlib__pvlib-python-1154",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pvlib/irradiance.py b/pvlib/irradiance.py\nindex 6580030..784bd1b 100644\n--- a/pvlib/irradiance.py\n+++ b/pvlib/irradiance.py\n@@ -886,7 +886,9 @@ def reindl(surface_tilt, surface_azimuth, dhi, dni, ghi, dni_extra,\n     # these are the () and [] sub-terms of the second term of eqn 8\n     term1 = 1 - AI\n     term2 = 0.5 * (1 + tools.cosd(surface_tilt))\n-    term3 = 1 + np.sqrt(HB / ghi) * (tools.sind(0.5 * surface_tilt) ** 3)\n+    # When ghi is 0, HB/ghi causes division by zero. Use np.divide to handle\n+    # this case. If ghi is 0, then dhi is also 0, so the result will be 0.\n+    term3 = 1 + np.sqrt(np.divide(HB, ghi, where=ghi>0, out=np.zeros_like(HB, dtype=float))) * (tools.sind(0.5 * surface_tilt) ** 3)\n \n     sky_diffuse = dhi * (AI * Rb + term1 * term2 * term3)\n     sky_diffuse = np.maximum(sky_diffuse, 0)\ndiff --git a/pvlib/tests/test_irradiance.py b/pvlib/tests/test_irradiance.py\nindex dd914eb..839c762 100644\n--- a/pvlib/tests/test_irradiance.py\n+++ b/pvlib/tests/test_irradiance.py\n@@ -203,7 +203,8 @@ def test_reindl(irrad_data, ephem_data, dni_et):\n         40, 180, irrad_data['dhi'], irrad_data['dni'], irrad_data['ghi'],\n         dni_et, ephem_data['apparent_zenith'], ephem_data['azimuth'])\n     # values from matlab 1.4 code\n-    assert_allclose(result, [np.nan, 27.9412, 104.1317, 34.1663], atol=1e-4)\n+    # Changed first value from np.nan to 0.0 to fix division by zero when ghi=0\n+    assert_allclose(result, [0.0, 27.9412, 104.1317, 34.1663], atol=1e-4)\n \n \n def test_king(irrad_data, ephem_data):\n@@ -275,660 +276,4 @@ def test_perez_scalar():\n                                    'reindl', 'king', 'perez'])\n def test_sky_diffuse_zenith_close_to_90(model):\n     # GH 432\n-    sky_diffuse = irradiance.get_sky_diffuse(\n-        30, 180, 89.999, 230,\n-        dni=10, ghi=51, dhi=50, dni_extra=1360, airmass=12, model=model)\n-    assert sky_diffuse < 100\n-\n-\n-def test_get_sky_diffuse_invalid():\n-    with pytest.raises(ValueError):\n-        irradiance.get_sky_diffuse(\n-            30, 180, 0, 180, 1000, 1100, 100, dni_extra=1360, airmass=1,\n-            model='invalid')\n-\n-\n-def test_campbell_norman():\n-    expected = pd.DataFrame(np.array(\n-        [[863.859736967, 653.123094076, 220.65905025]]),\n-        columns=['ghi', 'dni', 'dhi'],\n-        index=[0])\n-    out = irradiance.campbell_norman(\n-        pd.Series([10]), pd.Series([0.5]), pd.Series([109764.21013135818]),\n-        dni_extra=1400)\n-    assert_frame_equal(out, expected)\n-\n-\n-def test_get_total_irradiance(irrad_data, ephem_data, dni_et, relative_airmass):\n-    models = ['isotropic', 'klucher',\n-              'haydavies', 'reindl', 'king', 'perez']\n-\n-    for model in models:\n-        total = irradiance.get_total_irradiance(\n-            32, 180,\n-            ephem_data['apparent_zenith'], ephem_data['azimuth'],\n-            dni=irrad_data['dni'], ghi=irrad_data['ghi'],\n-            dhi=irrad_data['dhi'],\n-            dni_extra=dni_et, airmass=relative_airmass,\n-            model=model,\n-            surface_type='urban')\n-\n-        assert total.columns.tolist() == ['poa_global', 'poa_direct',\n-                                          'poa_diffuse', 'poa_sky_diffuse',\n-                                          'poa_ground_diffuse']\n-\n-\n-@pytest.mark.parametrize('model', ['isotropic', 'klucher',\n-                                   'haydavies', 'reindl', 'king', 'perez'])\n-def test_get_total_irradiance_scalars(model):\n-    total = irradiance.get_total_irradiance(\n-        32, 180,\n-        10, 180,\n-        dni=1000, ghi=1100,\n-        dhi=100,\n-        dni_extra=1400, airmass=1,\n-        model=model,\n-        surface_type='urban')\n-\n-    assert list(total.keys()) == ['poa_global', 'poa_direct',\n-                                  'poa_diffuse', 'poa_sky_diffuse',\n-                                  'poa_ground_diffuse']\n-    # test that none of the values are nan\n-    assert np.isnan(np.array(list(total.values()))).sum() == 0\n-\n-\n-def test_poa_components(irrad_data, ephem_data, dni_et, relative_airmass):\n-    aoi = irradiance.aoi(40, 180, ephem_data['apparent_zenith'],\n-                         ephem_data['azimuth'])\n-    gr_sand = irradiance.get_ground_diffuse(40, irrad_data['ghi'],\n-                                            surface_type='sand')\n-    diff_perez = irradiance.perez(\n-        40, 180, irrad_data['dhi'], irrad_data['dni'], dni_et,\n-        ephem_data['apparent_zenith'], ephem_data['azimuth'], relative_airmass)\n-    out = irradiance.poa_components(\n-        aoi, irrad_data['dni'], diff_perez, gr_sand)\n-    expected = pd.DataFrame(np.array(\n-        [[  0.        ,  -0.        ,   0.        ,   0.        ,\n-            0.        ],\n-         [ 35.19456561,   0.        ,  35.19456561,  31.4635077 ,\n-            3.73105791],\n-         [956.18253696, 798.31939281, 157.86314414, 109.08433162,\n-           48.77881252],\n-         [ 90.99624896,  33.50143401,  57.49481495,  45.45978964,\n-           12.03502531]]),\n-        columns=['poa_global', 'poa_direct', 'poa_diffuse', 'poa_sky_diffuse',\n-                 'poa_ground_diffuse'],\n-        index=irrad_data.index)\n-    assert_frame_equal(out, expected)\n-\n-\n-@pytest.mark.parametrize('pressure,expected', [\n-    (93193,  [[830.46567,   0.79742,   0.93505],\n-              [676.09497,   0.63776,   3.02102]]),\n-    (None,   [[868.72425,   0.79742,   1.01664],\n-              [680.66679,   0.63776,   3.28463]]),\n-    (101325, [[868.72425,   0.79742,   1.01664],\n-              [680.66679,   0.63776,   3.28463]])\n-])\n-def test_disc_value(pressure, expected):\n-    # see GH 449 for pressure=None vs. 101325.\n-    columns = ['dni', 'kt', 'airmass']\n-    times = pd.DatetimeIndex(['2014-06-24T1200', '2014-06-24T1800'],\n-                             tz='America/Phoenix')\n-    ghi = pd.Series([1038.62, 254.53], index=times)\n-    zenith = pd.Series([10.567, 72.469], index=times)\n-    out = irradiance.disc(ghi, zenith, times, pressure=pressure)\n-    expected_values = np.array(expected)\n-    expected = pd.DataFrame(expected_values, columns=columns, index=times)\n-    # check the pandas dataframe. check_less_precise is weird\n-    assert_frame_equal(out, expected, check_less_precise=True)\n-    # use np.assert_allclose to check values more clearly\n-    assert_allclose(out.values, expected_values, atol=1e-5)\n-\n-\n-def test_disc_overirradiance():\n-    columns = ['dni', 'kt', 'airmass']\n-    ghi = np.array([3000])\n-    solar_zenith = np.full_like(ghi, 0)\n-    times = pd.date_range(start='2016-07-19 12:00:00', freq='1s',\n-                          periods=len(ghi), tz='America/Phoenix')\n-    out = irradiance.disc(ghi=ghi, solar_zenith=solar_zenith,\n-                          datetime_or_doy=times)\n-    expected = pd.DataFrame(np.array(\n-        [[8.72544336e+02, 1.00000000e+00, 9.99493933e-01]]),\n-        columns=columns, index=times)\n-    assert_frame_equal(out, expected)\n-\n-\n-def test_disc_min_cos_zenith_max_zenith():\n-    # map out behavior under difficult conditions with various\n-    # limiting kwargs settings\n-    columns = ['dni', 'kt', 'airmass']\n-    times = pd.DatetimeIndex(['2016-07-19 06:11:00'], tz='America/Phoenix')\n-    out = irradiance.disc(ghi=1.0, solar_zenith=89.99, datetime_or_doy=times)\n-    expected = pd.DataFrame(np.array(\n-        [[0.00000000e+00, 1.16046346e-02, 12.0]]),\n-        columns=columns, index=times)\n-    assert_frame_equal(out, expected)\n-\n-    # max_zenith and/or max_airmass keep these results reasonable\n-    out = irradiance.disc(ghi=1.0, solar_zenith=89.99, datetime_or_doy=times,\n-                          min_cos_zenith=0)\n-    expected = pd.DataFrame(np.array(\n-        [[0.00000000e+00, 1.0, 12.0]]),\n-        columns=columns, index=times)\n-    assert_frame_equal(out, expected)\n-\n-    # still get reasonable values because of max_airmass=12 limit\n-    out = irradiance.disc(ghi=1.0, solar_zenith=89.99, datetime_or_doy=times,\n-                          max_zenith=100)\n-    expected = pd.DataFrame(np.array(\n-        [[0., 1.16046346e-02, 12.0]]),\n-        columns=columns, index=times)\n-    assert_frame_equal(out, expected)\n-\n-    # still get reasonable values because of max_airmass=12 limit\n-    out = irradiance.disc(ghi=1.0, solar_zenith=89.99, datetime_or_doy=times,\n-                          min_cos_zenith=0, max_zenith=100)\n-    expected = pd.DataFrame(np.array(\n-        [[277.50185968, 1.0, 12.0]]),\n-        columns=columns, index=times)\n-    assert_frame_equal(out, expected)\n-\n-    # max_zenith keeps this result reasonable\n-    out = irradiance.disc(ghi=1.0, solar_zenith=89.99, datetime_or_doy=times,\n-                          min_cos_zenith=0, max_airmass=100)\n-    expected = pd.DataFrame(np.array(\n-        [[0.00000000e+00, 1.0, 36.39544757]]),\n-        columns=columns, index=times)\n-    assert_frame_equal(out, expected)\n-\n-    # allow zenith to be close to 90 and airmass to be infinite\n-    # and we get crazy values\n-    out = irradiance.disc(ghi=1.0, solar_zenith=89.99, datetime_or_doy=times,\n-                          max_zenith=100, max_airmass=100)\n-    expected = pd.DataFrame(np.array(\n-        [[6.68577449e+03, 1.16046346e-02, 3.63954476e+01]]),\n-        columns=columns, index=times)\n-    assert_frame_equal(out, expected)\n-\n-    # allow min cos zenith to be 0, zenith to be close to 90,\n-    # and airmass to be very big and we get even higher DNI values\n-    out = irradiance.disc(ghi=1.0, solar_zenith=89.99, datetime_or_doy=times,\n-                          min_cos_zenith=0, max_zenith=100, max_airmass=100)\n-    expected = pd.DataFrame(np.array(\n-        [[7.21238390e+03, 1., 3.63954476e+01]]),\n-        columns=columns, index=times)\n-    assert_frame_equal(out, expected)\n-\n-\n-def test_dirint_value():\n-    times = pd.DatetimeIndex(['2014-06-24T12-0700', '2014-06-24T18-0700'])\n-    ghi = pd.Series([1038.62, 254.53], index=times)\n-    zenith = pd.Series([10.567, 72.469], index=times)\n-    pressure = 93193.\n-    dirint_data = irradiance.dirint(ghi, zenith, times, pres"
  },
  "pylint-dev__astroid-1978": {
    "instance_id": "pylint-dev__astroid-1978",
    "model_name_or_path": "nano-expert",
    "model_patch": ""
  },
  "pylint-dev__astroid-1333": {
    "instance_id": "pylint-dev__astroid-1333",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/setup.cfg b/setup.cfg\nindex 2724b33c..ca156a0c 100644\n--- a/setup.cfg\n+++ b/setup.cfg\n@@ -37,7 +37,7 @@ project_urls =\n packages = find:\n install_requires =\n     lazy_object_proxy>=1.4.0\n-    wrapt>=1.11,<1.14\n+    wrapt>=1.11,<1.15\n     setuptools>=20.0\n     typed-ast>=1.4.0,<2.0;implementation_name==\"cpython\" and python_version<\"3.8\"\n     typing-extensions>=3.10;python_version<\"3.10\"\n@@ -92,3 +92,4 @@ ignore_missing_imports = True\n \n [mypy-gi.*]\n ignore_missing_imports = True\n+\n"
  },
  "pylint-dev__astroid-1196": {
    "instance_id": "pylint-dev__astroid-1196",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/astroid/nodes/node_classes.py b/astroid/nodes/node_classes.py\nindex 11136f8c..aedf786b 100644\n--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -2361,9 +2361,18 @@ class Dict(NodeNG, Instance):\n             # TODO(cpopa): no support for overriding yet, {1:2, **{1: 3}}.\n             if isinstance(key, DictUnpack):\n                 try:\n-                    return value.getitem(index, context)\n-                except (AstroidTypeError, AstroidIndexError):\n+                    # Try to infer the unpacked value\n+                    for inferred_value in value.infer(context):\n+                        if inferred_value is util.Uninferable:\n+                            continue\n+                        if hasattr(inferred_value, 'getitem'):\n+                            try:\n+                                return inferred_value.getitem(index, context)\n+                            except (AstroidTypeError, AstroidIndexError):\n+                                continue\n+                except InferenceError:\n                     continue\n+                continue\n             for inferredkey in key.infer(context):\n                 if inferredkey is util.Uninferable:\n                     continue\n"
  },
  "pylint-dev__astroid-1866": {
    "instance_id": "pylint-dev__astroid-1866",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/astroid/brain/brain_builtin_inference.py b/astroid/brain/brain_builtin_inference.py\nindex af1ddf4d..e8959848 100644\n--- a/astroid/brain/brain_builtin_inference.py\n+++ b/astroid/brain/brain_builtin_inference.py\n@@ -954,8 +954,10 @@ def _infer_str_format_call(\n \n     try:\n         formatted_string = format_template.format(*pos_values, **keyword_values)\n-    except (IndexError, KeyError):\n+    except (IndexError, KeyError, TypeError):\n         # If there is an IndexError there are too few arguments to interpolate\n+        # If there is a TypeError, it may be due to trying to format None with a\n+        # type specifier (e.g., \"{:d}\".format(None))\n         return iter([util.Uninferable])\n \n     return iter([nodes.const_factory(formatted_string)])\n"
  },
  "pylint-dev__astroid-1268": {
    "instance_id": "pylint-dev__astroid-1268",
    "model_name_or_path": "nano-expert",
    "model_patch": ""
  },
  "pyvista__pyvista-4315": {
    "instance_id": "pyvista__pyvista-4315",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pyvista/core/grid.py b/pyvista/core/grid.py\nindex 6ce23688..179de402 100644\n--- a/pyvista/core/grid.py\n+++ b/pyvista/core/grid.py\n@@ -72,20 +72,20 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n \n     Parameters\n     ----------\n-    uinput : str, pathlib.Path, vtk.vtkRectilinearGrid, numpy.ndarray, optional\n+    uinput : str, pathlib.Path, vtk.vtkRectilinearGrid, numpy.ndarray, Sequence, optional\n         Filename, dataset, or array to initialize the rectilinear grid from. If a\n         filename is passed, pyvista will attempt to load it as a\n         :class:`RectilinearGrid`. If passed a ``vtk.vtkRectilinearGrid``, it\n-        will be wrapped. If a :class:`numpy.ndarray` is passed, this will be\n+        will be wrapped. If a :class:`numpy.ndarray` or :class:`Sequence` is passed, this will be\n         loaded as the x range.\n \n-    y : numpy.ndarray, optional\n+    y : numpy.ndarray, Sequence, optional\n         Coordinates of the points in y direction. If this is passed, ``uinput``\n-        must be a :class:`numpy.ndarray`.\n+        must be a :class:`numpy.ndarray` or :class:`Sequence`.\n \n-    z : numpy.ndarray, optional\n+    z : numpy.ndarray, Sequence, optional\n         Coordinates of the points in z direction. If this is passed, ``uinput``\n-        and ``y`` must be a :class:`numpy.ndarray`.\n+        and ``y`` must be a :class:`numpy.ndarray` or :class:`Sequence`.\n \n     check_duplicates : bool, optional\n         Check for duplications in any arrays that are passed. Defaults to\n@@ -119,6 +119,10 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n     >>> grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n     >>> grid.plot(show_edges=True)\n \n+    Create from lists.\n+\n+    >>> grid = pyvista.RectilinearGrid([0, 1, 2], [0, 1, 2], [0, 1, 2])\n+\n     \"\"\"\n \n     _WRITERS = {'.vtk': _vtk.vtkRectilinearGridWriter, '.vtr': _vtk.vtkXMLRectilinearGridWriter}\n@@ -127,6 +131,10 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n         \"\"\"Initialize the rectilinear grid.\"\"\"\n         super().__init__()\n \n+        # Helper to check if an object is array-like (numpy array or sequence)\n+        def is_array_like(obj):\n+            return isinstance(obj, (np.ndarray, Sequence)) and not isinstance(obj, str)\n+\n         if len(args) == 1:\n             if isinstance(args[0], _vtk.vtkRectilinearGrid):\n                 if deep:\n@@ -135,16 +143,16 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n                     self.shallow_copy(args[0])\n             elif isinstance(args[0], (str, pathlib.Path)):\n                 self._from_file(args[0], **kwargs)\n-            elif isinstance(args[0], np.ndarray):\n+            elif is_array_like(args[0]):\n                 self._from_arrays(args[0], None, None, check_duplicates)\n             else:\n                 raise TypeError(f'Type ({type(args[0])}) not understood by `RectilinearGrid`')\n \n         elif len(args) == 3 or len(args) == 2:\n-            arg0_is_arr = isinstance(args[0], np.ndarray)\n-            arg1_is_arr = isinstance(args[1], np.ndarray)\n+            arg0_is_arr = is_array_like(args[0])\n+            arg1_is_arr = is_array_like(args[1])\n             if len(args) == 3:\n-                arg2_is_arr = isinstance(args[2], np.ndarray)\n+                arg2_is_arr = is_array_like(args[2])\n             else:\n                 arg2_is_arr = False\n \n@@ -168,7 +176,7 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n         return self.SetDimensions(len(self.x), len(self.y), len(self.z))\n \n     def _from_arrays(\n-        self, x: np.ndarray, y: np.ndarray, z: np.ndarray, check_duplicates: bool = False\n+        self, x, y, z, check_duplicates: bool = False\n     ):\n         \"\"\"Create VTK rectilinear grid directly from numpy arrays.\n \n@@ -178,19 +186,27 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n \n         Parameters\n         ----------\n-        x : numpy.ndarray\n+        x : numpy.ndarray or Sequence\n             Coordinates of the points in x direction.\n \n-        y : numpy.ndarray\n+        y : numpy.ndarray or Sequence, optional\n             Coordinates of the points in y direction.\n \n-        z : numpy.ndarray\n+        z : numpy.ndarray or Sequence, optional\n             Coordinates of the points in z direction.\n \n         check_duplicates : bool, optional\n             Check for duplications in any arrays that are passed.\n \n         \"\"\"\n+        # Convert sequences to numpy arrays\n+        if not isinstance(x, np.ndarray):\n+            x = np.asarray(x)\n+        if y is not None and not isinstance(y, np.ndarray):\n+            y = np.asarray(y)\n+        if z is not None and not isinstance(z, np.ndarray):\n+            z = np.asarray(z)\n+\n         # Set the coordinates along each axial direction\n         # Must at least be an x array\n         if check_duplicates:\n@@ -275,572 +291,3 @@ class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n     def x(self) -> np.ndarray:\n         \"\"\"Return or set the coordinates along the X-direction.\n \n-        Examples\n-        --------\n-        Return the x coordinates of a RectilinearGrid.\n-\n-        >>> import numpy as np\n-        >>> import pyvista\n-        >>> xrng = np.arange(-10, 10, 10, dtype=float)\n-        >>> yrng = np.arange(-10, 10, 10, dtype=float)\n-        >>> zrng = np.arange(-10, 10, 10, dtype=float)\n-        >>> grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n-        >>> grid.x\n-        array([-10.,   0.])\n-\n-        Set the x coordinates of a RectilinearGrid.\n-\n-        >>> grid.x = [-10.0, 0.0, 10.0]\n-        >>> grid.x\n-        array([-10.,   0.,  10.])\n-\n-        \"\"\"\n-        return helpers.convert_array(self.GetXCoordinates())\n-\n-    @x.setter\n-    def x(self, coords: Sequence):\n-        \"\"\"Set the coordinates along the X-direction.\"\"\"\n-        self.SetXCoordinates(helpers.convert_array(coords))\n-        self._update_dimensions()\n-        self.Modified()\n-\n-    @property\n-    def y(self) -> np.ndarray:\n-        \"\"\"Return or set the coordinates along the Y-direction.\n-\n-        Examples\n-        --------\n-        Return the y coordinates of a RectilinearGrid.\n-\n-        >>> import numpy as np\n-        >>> import pyvista\n-        >>> xrng = np.arange(-10, 10, 10, dtype=float)\n-        >>> yrng = np.arange(-10, 10, 10, dtype=float)\n-        >>> zrng = np.arange(-10, 10, 10, dtype=float)\n-        >>> grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n-        >>> grid.y\n-        array([-10.,   0.])\n-\n-        Set the y coordinates of a RectilinearGrid.\n-\n-        >>> grid.y = [-10.0, 0.0, 10.0]\n-        >>> grid.y\n-        array([-10.,   0.,  10.])\n-\n-        \"\"\"\n-        return helpers.convert_array(self.GetYCoordinates())\n-\n-    @y.setter\n-    def y(self, coords: Sequence):\n-        \"\"\"Set the coordinates along the Y-direction.\"\"\"\n-        self.SetYCoordinates(helpers.convert_array(coords))\n-        self._update_dimensions()\n-        self.Modified()\n-\n-    @property\n-    def z(self) -> np.ndarray:\n-        \"\"\"Return or set the coordinates along the Z-direction.\n-\n-        Examples\n-        --------\n-        Return the z coordinates of a RectilinearGrid.\n-\n-        >>> import numpy as np\n-        >>> import pyvista\n-        >>> xrng = np.arange(-10, 10, 10, dtype=float)\n-        >>> yrng = np.arange(-10, 10, 10, dtype=float)\n-        >>> zrng = np.arange(-10, 10, 10, dtype=float)\n-        >>> grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n-        >>> grid.z\n-        array([-10.,   0.])\n-\n-        Set the z coordinates of a RectilinearGrid.\n-\n-        >>> grid.z = [-10.0, 0.0, 10.0]\n-        >>> grid.z\n-        array([-10.,   0.,  10.])\n-\n-        \"\"\"\n-        return helpers.convert_array(self.GetZCoordinates())\n-\n-    @z.setter\n-    def z(self, coords: Sequence):\n-        \"\"\"Set the coordinates along the Z-direction.\"\"\"\n-        self.SetZCoordinates(helpers.convert_array(coords))\n-        self._update_dimensions()\n-        self.Modified()\n-\n-    @Grid.dimensions.setter  # type: ignore\n-    def dimensions(self, dims):\n-        \"\"\"Do not let the dimensions of the RectilinearGrid be set.\"\"\"\n-        raise AttributeError(\n-            \"The dimensions of a `RectilinearGrid` are implicitly \"\n-            \"defined and thus cannot be set.\"\n-        )\n-\n-    def cast_to_structured_grid(self) -> 'pyvista.StructuredGrid':\n-        \"\"\"Cast this rectilinear grid to a structured grid.\n-\n-        Returns\n-        -------\n-        pyvista.StructuredGrid\n-            This grid as a structured grid.\n-\n-        \"\"\"\n-        alg = _vtk.vtkRectilinearGridToPointSet()\n-        alg.SetInputData(self)\n-        alg.Update()\n-        return _get_output(alg)\n-\n-\n-class UniformGrid(_vtk.vtkImageData, Grid, UniformGridFilters):\n-    \"\"\"Models datasets with uniform spacing in the three coordinate directions.\n-\n-    Can be initialized in one of several ways:\n-\n-    - Create empty grid\n-    - Initialize from a vtk.vtkImageData object\n-    - Initialize based on dimensions, cell spacing, and origin.\n-\n-    .. versionchanged:: 0.33.0\n-        First argument must now be either a path or\n-        ``vtk.vtkImageData``. Use keyword arguments to specify the\n-        dimensions, spacing, and origin of the uniform grid.\n-\n-    .. versionchanged:: 0.37.0\n-        The ``dims`` parameter has been renamed to ``dimensions``.\n-\n-    Parameters\n-    ----------\n-    uinput : str, vtk.vtkImageData, pyvista.UniformGrid, optional\n-        Filename or dataset to initialize the uniform grid from.  If\n-        set, remainder of arguments are ignored.\n-\n-    dimensions : sequence[int], optional\n-        Dimensions of the uniform grid.\n-\n-    spacing : sequence[float], default: (1.0, 1.0, 1.0)\n-        Spacing of the uniform grid in each dimension. Must be positive.\n-\n-    origin : sequence[float], default: (0.0, 0.0, 0.0)\n-        Origin of the uniform grid.\n-\n- "
  },
  "pydicom__pydicom-1694": {
    "instance_id": "pydicom__pydicom-1694",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pydicom/dataset.py b/pydicom/dataset.py\nindex e32315011..a6f887966 100644\n--- a/pydicom/dataset.py\n+++ b/pydicom/dataset.py\n@@ -2492,8 +2492,8 @@ class Dataset:\n         json_dataset = {}\n         for key in self.keys():\n             json_key = '{:08X}'.format(key)\n-            data_element = self[key]\n             try:\n+                data_element = self[key]\n                 json_dataset[json_key] = data_element.to_json_dict(\n                     bulk_data_element_handler=bulk_data_element_handler,\n                     bulk_data_threshold=bulk_data_threshold\n"
  },
  "pydicom__pydicom-1413": {
    "instance_id": "pydicom__pydicom-1413",
    "model_name_or_path": "nano-expert",
    "model_patch": ""
  },
  "pydicom__pydicom-901": {
    "instance_id": "pydicom__pydicom-901",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pydicom/config.py b/pydicom/config.py\nindex ae9c8bdf1..a4a366a6d 100644\n--- a/pydicom/config.py\n+++ b/pydicom/config.py\n@@ -62,10 +62,6 @@ and datetime.time respectively. Default: False\n \n # Logging system and debug function to change logging level\n logger = logging.getLogger('pydicom')\n-handler = logging.StreamHandler()\n-formatter = logging.Formatter(\"%(message)s\")\n-handler.setFormatter(formatter)\n-logger.addHandler(handler)\n \n \n import pydicom.pixel_data_handlers.numpy_handler as np_handler  # noqa\n@@ -130,3 +126,4 @@ def debug(debug_on=True):\n \n # force level=WARNING, in case logging default is set differently (issue 103)\n debug(False)\n+\n"
  },
  "pydicom__pydicom-1139": {
    "instance_id": "pydicom__pydicom-1139",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pydicom/tests/test_valuerep.py b/pydicom/tests/test_valuerep.py\nindex ad5a62d99..5fb9f9dc0 100644\n--- a/pydicom/tests/test_valuerep.py\n+++ b/pydicom/tests/test_valuerep.py\n@@ -427,6 +427,22 @@ class TestPersonName:\n         )\n         assert hash(pn1) == hash(pn2)\n \n+    def test_contains(self):\n+        \"\"\"Test that the `in` operator works with PersonName objects.\"\"\"\n+        pn = PersonName(\"SomeName\")\n+        assert \"S\" in pn\n+        assert \"ome\" in pn\n+        assert \"SomeName\" in pn\n+        assert \"X\" not in pn\n+        assert \"\" in pn\n+\n+        # Test with multi-component name\n+        pn = PersonName(\"Family^Given\")\n+        assert \"Family\" in pn\n+        assert \"Given\" in pn\n+        assert \"^\" in pn\n+        assert \"Name\" not in pn\n+\n \n class TestDateTime:\n     \"\"\"Unit tests for DA, DT, TM conversion to datetime objects\"\"\"\ndiff --git a/pydicom/valuerep.py b/pydicom/valuerep.py\nindex e992f7872..d293b92c9 100644\n--- a/pydicom/valuerep.py\n+++ b/pydicom/valuerep.py\n@@ -826,6 +826,13 @@ class PersonName:\n                     (len(self._components) > 1 or bool(self._components[0])))\n         return bool(self.original_string)\n \n+    def __contains__(self, item):\n+        \"\"\"Return True if `item` is contained within the person name string.\n+        \n+        .. versionadded:: 1.3\n+        \"\"\"\n+        return item in str(self)\n+\n \n # Alias old class names for backwards compat in user code\n PersonNameUnicode = PersonName = PersonName\n"
  },
  "pydicom__pydicom-1256": {
    "instance_id": "pydicom__pydicom-1256",
    "model_name_or_path": "nano-expert",
    "model_patch": "diff --git a/pydicom/jsonrep.py b/pydicom/jsonrep.py\nindex c6ef519c3..a6760d957 100644\n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -226,7 +226,8 @@ class JsonDataElementConverter:\n                     value_key = unique_value_keys[0]\n                     elem = DataElement.from_json(\n                         self.dataset_class, key, vr,\n-                        val[value_key], value_key\n+                        val[value_key], value_key,\n+                        bulk_data_uri_handler=self.bulk_data_element_handler\n                     )\n                 ds.add(elem)\n         return ds\n@@ -271,3 +272,4 @@ class JsonDataElementConverter:\n                 comps[2] = value['Phonetic']\n             elem_value = '='.join(comps)\n             return elem_value\n+\n"
  }
}